Cola report
==================

**Date**: `r Sys.Date()`

----------------------------------------------------------------

<style type='text/css'>
#toc {
  position: fixed;
  left: 0;
  top: 20px;
  width: 200px;
  height: 100%;
  overflow:auto;
  padding: 0px 10px 0px 10px;
}
#toc_header {
  display: none;
}
#toc ul {
  margin: 0px;
  padding: 0px;
}
#toc ul li {
  list-style-type: none;
}

#toc ul li ul li {
  margin-left: 15px;
  list-style-type: circle;
}
body, td, th {
   font-family: Arial,Helvetica,sans-serif;
   background-color: white;
   font-size: 13px;
  max-width: 800px;
  margin: auto;
  margin-left:210px;
  padding: 0px 10px 0px 10px;
  border-left: 1px solid #EEEEEE;
  line-height: 150%;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, 

monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a {
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: 1px solid #ccc;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>

```{r, echo = FALSE, message = FALSE}
library(knitr)
library(markdown)
options(markdown.HTML.options = setdiff(c(getOption("markdown.HTML.options"), "toc"), "base64_images"))
options(width = 100)
options(digits = 3)
opts_chunk$set(
	comment = "#>",
	fig.path = "figure_cola/",
	warning = FALSE,
	message = FALSE
)
suppressPackageStartupMessages(library(ComplexHeatmap))
suppressPackageStartupMessages(library(genefilter))
```



## Summary



First the variable name is changed to `res_list`.

```{r, eval = FALSE, echo = TRUE}
res_list = rl
```

```{r, echo = FALSE}
res_list = object
```

All available functions which can be applied to this `res_list` object:

```{r}
res_list
```

The call of `run_all_consensus_partition_methods()` was:

```{r, echo = FALSE}
print(res_list@calling)
```

Dimension of the input matrix:

```{r}
mat = get_matrix(res_list)
dim(mat)
```

The density distribution for each sample is visualized as heatmap as one column in follwing plot:

```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message(qq("* making density heatmap of global distribution in each sample (@{ncol(mat)} samples)"), appendLF = FALSE)
```

```{r density-heatmap}
library(ComplexHeatmap)
densityHeatmap(mat, top_annotation = HeatmapAnnotation(df = get_anno(res_list), 
	col = get_anno_col(res_list)), ylab = "value", cluster_columns = TRUE, show_column_names = FALSE)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))))
```

```{r, echo = FALSE, message = FALSE}
n_top_value_method = length(res_list@top_value_method)
n_partition_method = length(res_list@partition_method)
n_method = n_top_value_method * n_partition_method
message(qq("* top rows are extracted by '@{paste(res_list@top_value_method, collapse = ', ')}' methods"))
message(qq("* subgroups are detected by '@{paste(res_list@partition_method, collapse = ', ')}' methods"))
message(qq("  - in total @{n_method} combinations of methods"))
```

`res_list` contains results for 	

```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("* guessing best k for each method", appendLF = FALSE)
```

Best `k` (number of partitions) for each combination of top value methods and partition methods:

```{r, eval = FALSE}
guess_best_k(res_list)
```

```{r, echo = FALSE}
tb = guess_best_k(res_list)
g = expand.grid(res_list@partition_method, res_list@top_value_method)
g = paste0(g[, 2], ":", g[, 1])
od = sapply(rownames(tb), function(x) which(g == x))
rownames(tb) = paste0("[", rownames(tb), "](#toc_", od + 2, ")")
kable(tb)
```

```{r, echo = FALSE}
fs = min(c(3*n_top_value_method, 14))/n_partition_method
```

CDF of consensus matrix for all methods:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* making empirical cumulative distribution curves for all methods"), appendLF = FALSE)
```

```{r collect-plots, fig.width = fs*n_partition_method, fig.height = fs*n_top_value_method, results = "hide"}
collect_plots(res_list, fun = plot_ecdf)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* making consensus heatmaps for all methods"), appendLF = FALSE)
```

Consensus heatmaps for all methods:

```{r, results = "asis", echo = FALSE, include = TRUE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - consensus heamtaps for all methods (k = 2)", appendLF = FALSE)
knitr_add_tab_item('collect_plots(res_list, k = 2, fun = consensus_heatmap)', 'k = 2', opt = 'fig.width = 15, fig.height = 12, results = "hide"')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - consensus heamtaps for all methods (k = 3)", appendLF = FALSE)
knitr_add_tab_item('collect_plots(res_list, k = 3, fun = consensus_heatmap)', 'k = 3', opt = 'fig.width = 15, fig.height = 12, results = "hide"')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - consensus heamtaps for all methods (k = 4)", appendLF = FALSE)
knitr_add_tab_item('collect_plots(res_list, k = 4, fun = consensus_heatmap)', 'k = 4', opt = 'fig.width = 15, fig.height = 12, results = "hide"')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - consensus heamtaps for all methods (k = 5)", appendLF = FALSE)
knitr_add_tab_item('collect_plots(res_list, k = 5, fun = consensus_heatmap)', 'k = 5', opt = 'fig.width = 15, fig.height = 12, results = "hide"')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - consensus heamtaps for all methods (k = 6)", appendLF = FALSE)
knitr_add_tab_item('collect_plots(res_list, k = 6, fun = consensus_heatmap)', 'k = 6', opt = 'fig.width = 15, fig.height = 12, results = "hide"')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* making membership heatmaps for all methods"), appendLF = FALSE)
```

Membership heatmaps for all methods:

```{r, results = "asis", echo = FALSE, include = TRUE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - membership heamtap for all methods (k = 2)", appendLF = FALSE)
knitr_add_tab_item('collect_plots(res_list, k = 2, fun = membership_heatmap)', 'k = 2', opt = 'fig.width =15, fig.height = 12, results = "hide"')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - membership heamtap for all methods (k = 3)", appendLF = FALSE)
knitr_add_tab_item('collect_plots(res_list, k = 3, fun = membership_heatmap)', 'k = 3', opt = 'fig.width =15, fig.height = 12, results = "hide"')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - membership heamtap for all methods (k = 4)", appendLF = FALSE)
knitr_add_tab_item('collect_plots(res_list, k = 4, fun = membership_heatmap)', 'k = 4', opt = 'fig.width =15, fig.height = 12, results = "hide"')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - membership heamtap for all methods (k = 5)", appendLF = FALSE)
knitr_add_tab_item('collect_plots(res_list, k = 5, fun = membership_heatmap)', 'k = 5', opt = 'fig.width =15, fig.height = 12, results = "hide"')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - membership heamtap for all methods (k = 6)", appendLF = FALSE)
knitr_add_tab_item('collect_plots(res_list, k = 6, fun = membership_heatmap)', 'k = 6', opt = 'fig.width =15, fig.height = 12, results = "hide"')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* making signature heatmaps for all methods"), appendLF = FALSE)
```

Signature heatmaps for all methods:

```{r, results = "asis", echo = FALSE, include = TRUE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - signature heamtap for all methods (k = 2)", appendLF = FALSE)
knitr_add_tab_item('collect_plots(res_list, k = 2, fun = get_signatures)', 'k = 2', opt = 'fig.width = 15, fig.height = 12, results = "hide"')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - signature heamtap for all methods (k = 3)", appendLF = FALSE)
knitr_add_tab_item('collect_plots(res_list, k = 3, fun = get_signatures)', 'k = 3', opt = 'fig.width = 15, fig.height = 12, results = "hide"')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - signature heamtap for all methods (k = 4)", appendLF = FALSE)
knitr_add_tab_item('collect_plots(res_list, k = 4, fun = get_signatures)', 'k = 4', opt = 'fig.width = 15, fig.height = 12, results = "hide"')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - signature heamtap for all methods (k = 5)", appendLF = FALSE)
knitr_add_tab_item('collect_plots(res_list, k = 5, fun = get_signatures)', 'k = 5', opt = 'fig.width = 15, fig.height = 12, results = "hide"')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - signature heamtap for all methods (k = 6)", appendLF = FALSE)
knitr_add_tab_item('collect_plots(res_list, k = 6, fun = get_signatures)', 'k = 6', opt = 'fig.width = 15, fig.height = 12, results = "hide"')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* getting statistics for all methods"), appendLF = FALSE)
```

Get statistics for all methods:

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_stat(res_list, k = 2)', 'k = 2')
knitr_add_tab_item('get_stat(res_list, k = 3)', 'k = 3')
knitr_add_tab_item('get_stat(res_list, k = 4)', 'k = 4')
knitr_add_tab_item('get_stat(res_list, k = 5)', 'k = 5')
knitr_add_tab_item('get_stat(res_list, k = 6)', 'k = 6')
knitr_insert_tabs()
```


```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* collecting classifications for all methods"), appendLF = FALSE)
```

Collect partitions from all methods:

```{r, results = "asis", echo = FALSE, include = TRUE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - classifications from all methods (k = 2)", appendLF = FALSE)
knitr_add_tab_item('collect_classes(res_list, k = 2)', 'k = 2', opt = 'fig.width = 8, fig.height = 8')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - classifications from all methods (k = 3)", appendLF = FALSE)
knitr_add_tab_item('collect_classes(res_list, k = 3)', 'k = 3', opt = 'fig.width = 8, fig.height = 8')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - classifications from all methods (k = 4)", appendLF = FALSE)
knitr_add_tab_item('collect_classes(res_list, k = 4)', 'k = 4', opt = 'fig.width = 8, fig.height = 8')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - classifications from all methods (k = 5)", appendLF = FALSE)
knitr_add_tab_item('collect_classes(res_list, k = 5)', 'k = 5', opt = 'fig.width = 8, fig.height = 8')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - classifications from all methods (k = 6)", appendLF = FALSE)
knitr_add_tab_item('collect_classes(res_list, k = 6)', 'k = 6', opt = 'fig.width = 8, fig.height = 8')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* overlaping top rows from different top value methods"), appendLF = FALSE)
```

Overlap of top rows in different top methods:


```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('top_rows_overlap(res_list, top_n = 1000, method = "venneuler")', 'top_n = 1000', opt = 'fig.width = 5, fig.height = 5')
knitr_add_tab_item('top_rows_overlap(res_list, top_n = 2000, method = "venneuler")', 'top_n = 2000', opt = 'fig.width = 5, fig.height = 5')
knitr_add_tab_item('top_rows_overlap(res_list, top_n = 3000, method = "venneuler")', 'top_n = 3000', opt = 'fig.width = 5, fig.height = 5')
knitr_add_tab_item('top_rows_overlap(res_list, top_n = 4000, method = "venneuler")', 'top_n = 4000', opt = 'fig.width = 5, fig.height = 5')
knitr_insert_tabs()
```

Also visualize the correspondance of rankings between different top methods:

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('top_rows_overlap(res_list, top_n = 1000, method = "correspondance")', 'top_n = 1000', opt = 'fig.width = 14, fig.height = 8')
knitr_add_tab_item('top_rows_overlap(res_list, top_n = 2000, method = "correspondance")', 'top_n = 2000', opt = 'fig.width = 14, fig.height = 8')
knitr_add_tab_item('top_rows_overlap(res_list, top_n = 3000, method = "correspondance")', 'top_n = 3000', opt = 'fig.width = 14, fig.height = 8')
knitr_add_tab_item('top_rows_overlap(res_list, top_n = 4000, method = "correspondance")', 'top_n = 4000', opt = 'fig.width = 14, fig.height = 8')
knitr_insert_tabs()
```

Heatmaps for the top rows:


```{r, results = "asis", echo = FALSE, include = TRUE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - comparing top row methods by heatmap (top_n = 1000)", appendLF = FALSE)
knitr_add_tab_item('top_rows_heatmap(res_list, top_n = 1000)', 'top_n = 1000', opt = 'fig.width = 14, fig.height = 3.5')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - comparing top row methods by heatmap (top_n = 2000)", appendLF = FALSE)
knitr_add_tab_item('top_rows_heatmap(res_list, top_n = 2000)', 'top_n = 2000', opt = 'fig.width = 14, fig.height = 3.5')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - comparing top row methods by heatmap (top_n = 3000)", appendLF = FALSE)
knitr_add_tab_item('top_rows_heatmap(res_list, top_n = 3000)', 'top_n = 3000', opt = 'fig.width = 14, fig.height = 3.5')
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - comparing top row methods by heatmap (top_n = 4000)", appendLF = FALSE)
knitr_add_tab_item('top_rows_heatmap(res_list, top_n = 4000)', 'top_n = 4000', opt = 'fig.width = 14, fig.height = 3.5')
knitr_insert_tabs()
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```

Test correlation between subgroups and known annotations:

```{r, results = 'asis', echo = FALSE, include = TRUE}
knitr_add_tab_item('test_to_known_factors(res_list, k = 2)', 'k = 2')
knitr_add_tab_item('test_to_known_factors(res_list, k = 3)', 'k = 3')
knitr_add_tab_item('test_to_known_factors(res_list, k = 4)', 'k = 4')
knitr_add_tab_item('test_to_known_factors(res_list, k = 5)', 'k = 5')
knitr_add_tab_item('test_to_known_factors(res_list, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```

 
## Results for each method

    	
---------------------------------------------------



### sd:hclust


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for sd:hclust (1/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["sd", "hclust"]
# you can also extract it by
# res = res_list["sd:hclust"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r sd-hclust-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r sd-hclust-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-hclust-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-hclust-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-hclust-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r sd-hclust-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-hclust-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r sd-hclust-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### sd:kmeans**


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for sd:kmeans (2/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["sd", "kmeans"]
# you can also extract it by
# res = res_list["sd:kmeans"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r sd-kmeans-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r sd-kmeans-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-kmeans-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-kmeans-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-kmeans-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r sd-kmeans-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-kmeans-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r sd-kmeans-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### sd:skmeans**


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for sd:skmeans (3/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["sd", "skmeans"]
# you can also extract it by
# res = res_list["sd:skmeans"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r sd-skmeans-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r sd-skmeans-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-skmeans-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-skmeans-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-skmeans-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r sd-skmeans-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-skmeans-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r sd-skmeans-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### sd:pam**


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for sd:pam (4/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["sd", "pam"]
# you can also extract it by
# res = res_list["sd:pam"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r sd-pam-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r sd-pam-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-pam-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-pam-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-pam-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r sd-pam-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-pam-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r sd-pam-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### sd:mclust**


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for sd:mclust (5/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["sd", "mclust"]
# you can also extract it by
# res = res_list["sd:mclust"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r sd-mclust-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r sd-mclust-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-mclust-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-mclust-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-mclust-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r sd-mclust-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r sd-mclust-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r sd-mclust-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### cv:hclust


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for cv:hclust (6/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["cv", "hclust"]
# you can also extract it by
# res = res_list["cv:hclust"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r cv-hclust-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r cv-hclust-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-hclust-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-hclust-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-hclust-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r cv-hclust-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-hclust-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r cv-hclust-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### cv:kmeans*


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for cv:kmeans (7/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["cv", "kmeans"]
# you can also extract it by
# res = res_list["cv:kmeans"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r cv-kmeans-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r cv-kmeans-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-kmeans-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-kmeans-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-kmeans-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r cv-kmeans-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-kmeans-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r cv-kmeans-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### cv:skmeans**


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for cv:skmeans (8/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["cv", "skmeans"]
# you can also extract it by
# res = res_list["cv:skmeans"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r cv-skmeans-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r cv-skmeans-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-skmeans-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-skmeans-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-skmeans-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r cv-skmeans-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-skmeans-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r cv-skmeans-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### cv:pam


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for cv:pam (9/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["cv", "pam"]
# you can also extract it by
# res = res_list["cv:pam"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r cv-pam-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r cv-pam-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-pam-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-pam-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-pam-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r cv-pam-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-pam-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r cv-pam-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### cv:mclust


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for cv:mclust (10/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["cv", "mclust"]
# you can also extract it by
# res = res_list["cv:mclust"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r cv-mclust-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r cv-mclust-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-mclust-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-mclust-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-mclust-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r cv-mclust-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r cv-mclust-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r cv-mclust-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### MAD:hclust


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for MAD:hclust (11/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["MAD", "hclust"]
# you can also extract it by
# res = res_list["MAD:hclust"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r MAD-hclust-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r MAD-hclust-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-hclust-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-hclust-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-hclust-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r MAD-hclust-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-hclust-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r MAD-hclust-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### MAD:kmeans**


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for MAD:kmeans (12/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["MAD", "kmeans"]
# you can also extract it by
# res = res_list["MAD:kmeans"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r MAD-kmeans-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r MAD-kmeans-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-kmeans-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-kmeans-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-kmeans-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r MAD-kmeans-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-kmeans-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r MAD-kmeans-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### MAD:skmeans**


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for MAD:skmeans (13/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["MAD", "skmeans"]
# you can also extract it by
# res = res_list["MAD:skmeans"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r MAD-skmeans-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r MAD-skmeans-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-skmeans-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-skmeans-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-skmeans-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r MAD-skmeans-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-skmeans-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r MAD-skmeans-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### MAD:pam**


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for MAD:pam (14/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["MAD", "pam"]
# you can also extract it by
# res = res_list["MAD:pam"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r MAD-pam-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r MAD-pam-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-pam-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-pam-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-pam-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r MAD-pam-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-pam-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r MAD-pam-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### MAD:mclust*


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for MAD:mclust (15/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["MAD", "mclust"]
# you can also extract it by
# res = res_list["MAD:mclust"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r MAD-mclust-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r MAD-mclust-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-mclust-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-mclust-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-mclust-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r MAD-mclust-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r MAD-mclust-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r MAD-mclust-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### AAC:hclust


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for AAC:hclust (16/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["AAC", "hclust"]
# you can also extract it by
# res = res_list["AAC:hclust"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r AAC-hclust-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r AAC-hclust-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-hclust-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-hclust-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-hclust-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r AAC-hclust-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-hclust-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r AAC-hclust-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### AAC:kmeans*


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for AAC:kmeans (17/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["AAC", "kmeans"]
# you can also extract it by
# res = res_list["AAC:kmeans"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r AAC-kmeans-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r AAC-kmeans-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-kmeans-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-kmeans-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-kmeans-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r AAC-kmeans-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-kmeans-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r AAC-kmeans-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### AAC:skmeans**


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for AAC:skmeans (18/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["AAC", "skmeans"]
# you can also extract it by
# res = res_list["AAC:skmeans"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r AAC-skmeans-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r AAC-skmeans-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-skmeans-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-skmeans-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-skmeans-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r AAC-skmeans-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-skmeans-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r AAC-skmeans-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### AAC:pam**


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for AAC:pam (19/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["AAC", "pam"]
# you can also extract it by
# res = res_list["AAC:pam"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r AAC-pam-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r AAC-pam-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-pam-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-pam-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-pam-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r AAC-pam-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-pam-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r AAC-pam-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.


    	
---------------------------------------------------



### AAC:mclust*


```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
message("* generating plots for AAC:mclust (20/20)")
```

The object with results only for a single top value method and a single partition method 
can be extracted as:

```{r}
res = res_list["AAC", "mclust"]
# you can also extract it by
# res = res_list["AAC:mclust"]
```

A summary of `res` and all the functions that can be applied to it:

```{r}
res
```

`collect_plots()` function collects all the plots made from `res` for all `k` (number of partitions)
into one single page to provide an easy and fast comparison between different `k`.


```{r, echo = FALSE, message = FALSE}
t1 = Sys.time()
message("  - collecting all plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

The plots are:

- The first row: a plot of the ECDF (Empirical cumulative distribution function) curves of the consensus matrix for each `k` and the heatmap of predicted
  classes for each `k`.
- The second row: heatmaps of the consensus matrix for each `k`.
- The third row: heatmaps of the membership matrix for each `k`.
- The fouth row: heatmaps of the signatures for each `k`.

All the plots in panels can be made by individual functions and they are plotted later in this section.

```{r AAC-mclust-collect-plots, fig.width = 15, fig.height = 12, results = "hide"}
collect_plots(res)
```

`select_partition_number()` produces several plots showing different statistics for choosing "optimized" `k`. There are following statistics:

- ECDF curves of the consensus matrix for each `k`;
- cophenetic correlation coefficient. It measures if hierarchical clustering is applied on the consensus matrix, how good it correlates to the consensus matrix itself. 
- PAC. This a variant of the orignial PAC (proportion of ambiguous clustering) method. For each $x_{1i}$ in `seq(0.1, 0.3, by = 0.02)` and $x_{2j}$ in `seq(0.7, 0.9, by = 0.02)`, $PAC_k = F(x_{2j}) - F(x_{1i})$ where $F(x)$ is the ECDF of the consensus matrix (the lower triangle matrix without diagnals). The final PAC is the mean of all $PAC_k$ by removing top 10 percent and bottom 10 percent of all values.
- mean silhouette score.
- concordance. The mean probability of fiting the consensus class ids in all partitions.
- area increased. Denote $A_k$ as the area under the ECDF curve for current `k`, the area increased is defined as $A_k - A_{k-1}$.
- Rand index. The percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of k and k-1.
- Jaccard index. The ratio of pairs of samples are both in a same cluster in the partition of k and k-1 and the pairs of samples are both in a same cluster in the partition k or k-1.

Generally speaking, higher cophenetic correlation coefficient, lower PAC score, higher mean silhouette score or higher concordance corresponds to better partition. Rand index and Jaccard index measure how similar the current partition is compared to partition with `k-1`. If they are too similar, we won't accept `k` is better than `k-1`.

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - plotting various statistics for selecting best k", appendLF = FALSE)
```

```{r AAC-mclust-select-partition-number, results = "hide", fig.width = 10}
select_partition_number(res)
```

The numeric values for all these statistics can be obtained by `get_stat()`.

```{r}
get_stat(res)
```

Guess the best `k` based on these statistics. The rule is as follows:

1. All `k` with Rand index larger than 0.95 are removed because the partition number increasement
  does not provides enough extra information.
2. For `k` with cophenetic correlation coefficient larger than 0.99 or PAC score less than 0.1 or oncordance larger than 0.95,
  the maximum `k` is taken as the "best `k`".
3. The `k` with highest cophenetic correlation coefficient, lowest PAC score, highest mean silhouette and highest
   concordance. The `k` with highest occurance is taken as the "best `k`".

```{r}
guess_best_k(res)
```

The table of the partitions. The membership matrix (columns with name `p*`) is inferred by [`clue::cl_consensus()`](https://www.rdocumentation.org/link/cl_consensus?package=clue)
function with the `SE` method. Basically the value in the membership matrix represents the probability to belong
to a certain group. The finall class label for an item is determined with the group with highest probability it belongs to.

In `get_classes()` function, the entropy is calculated from the membership matrix and the silhouette score
is calculated from the consensus matrix.

```{r, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('cbind(get_classes(res, k = 2), get_membership(res, k = 2))', 'k = 2')
knitr_add_tab_item('cbind(get_classes(res, k = 3), get_membership(res, k = 3))', 'k = 3')
knitr_add_tab_item('cbind(get_classes(res, k = 4), get_membership(res, k = 4))', 'k = 4')
knitr_add_tab_item('cbind(get_classes(res, k = 5), get_membership(res, k = 5))', 'k = 5')
knitr_add_tab_item('cbind(get_classes(res, k = 6), get_membership(res, k = 6))', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the consensus matrix:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making consensus heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-mclust-consensus-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('consensus_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('consensus_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('consensus_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('consensus_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('consensus_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

Heatmaps for the membership of samples in all partitions to see how consistent they are:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making membership heatmaps (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-mclust-membership-heatmap, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('membership_heatmap(res, k = 2)', 'k = 2')
knitr_add_tab_item('membership_heatmap(res, k = 3)', 'k = 3')
knitr_add_tab_item('membership_heatmap(res, k = 4)', 'k = 4')
knitr_add_tab_item('membership_heatmap(res, k = 5)', 'k = 5')
knitr_add_tab_item('membership_heatmap(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

As soon as we have had the classes for columns, we can look for signatures which are significantly
different between classes which can be candidate marks for certain classes.

Heatmaps for signatures:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - getting signatures (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-mclust-signature, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

```{r AAC-mclust-signature-no-scale, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('get_signatures(res, k = 2, scale_rows = FALSE)', 'k = 2', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 3, scale_rows = FALSE)', 'k = 3', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 4, scale_rows = FALSE)', 'k = 4', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 5, scale_rows = FALSE)', 'k = 5', opt = 'results = "hide"')
knitr_add_tab_item('get_signatures(res, k = 6, scale_rows = FALSE)', 'k = 6', opt = 'results = "hide"')
knitr_insert_tabs()
```

PCA plots:

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - making PCA plots (k = '2, 3, 4, 5, 6')", appendLF = FALSE)
```

```{r AAC-mclust-mds, results = "asis", echo = FALSE, include = TRUE}
knitr_add_tab_item('dimension_reduction(res, k = 2)', 'k = 2')
knitr_add_tab_item('dimension_reduction(res, k = 3)', 'k = 3')
knitr_add_tab_item('dimension_reduction(res, k = 4)', 'k = 4')
knitr_add_tab_item('dimension_reduction(res, k = 5)', 'k = 5')
knitr_add_tab_item('dimension_reduction(res, k = 6)', 'k = 6')
knitr_insert_tabs()
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message("  - collecting classifications for all k", appendLF = FALSE)
```

How subgroups split when increasing `k`:

```{r AAC-mclust-collect-classes}
collect_classes(res)
```



```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1)))); t1 = Sys.time()
message(qq("* testing correlation of subgroups to known annotations"), appendLF = FALSE)
```
	
Test to known annotations:

```{r, eval = !is.null(res@anno), echo = !is.null(res@anno)}
test_to_known_factors(res)
```

```{r, echo = FALSE, message = FALSE}
t2 = Sys.time(); message(paste0(", ", gsub("^ +", "", format(t2 - t1))));
```



Consider to use `submit_to_david()` to do function enrichment for each signature list.



## Session info

```{r}
sessionInfo()
```

```{r, echo = FALSE, message = FALSE}
message("-----------------------------------------------------------------")
```
